{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of Step_2_3_DataSets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliElkeshawy/python1/blob/master/Copy_of_Step_2_3_DataSets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6OzHNTtkkDh",
        "colab_type": "code",
        "outputId": "387bd0b2-ba62-440c-fc34-40c8319b023c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0rc0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (46.0.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LGu1Y30iX3K",
        "colab_type": "code",
        "outputId": "34a4d641-1eeb-4974-f4ec-9ea088cdb348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfMgLG8XzyFi",
        "colab_type": "code",
        "outputId": "2fcae0d5-7c1c-4a34-e3c8-e80eca027f23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import itertools \n",
        "import collections\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) # the simplest way to create a dataset is to create it from a python list:\n",
        "for element in dataset: \n",
        "  print(element)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMKDkbwtzyFw",
        "colab_type": "code",
        "outputId": "8cd2b2f8-f40f-4fbb-e5ed-8bf428fb1aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#dataset = tf.data.TextLineDataset([\"file1.txt\", \"file2.txt\"])  # To process lines from files, use tf.data.TextLineDataset0\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.map(lambda x: x*2) #  Once you have a dataset, you can apply transformations to prepare the data for your model:\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsG6sLe8zyF7",
        "colab_type": "code",
        "outputId": "ad1bad3d-1a61-4d6a-d49f-c61f6caf12a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Creates a dataset of a step-separated range of values\n",
        "list(dataset.range(5).as_numpy_iterator()) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUhg1S38zyGJ",
        "colab_type": "code",
        "outputId": "736a9670-f0b8-42f3-ffee-e478dbafe26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(2, 5).as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6rOGVWbzyGT",
        "colab_type": "code",
        "outputId": "8d85143c-871f-4bf5-a4e4-73207c15cd31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(1, 5, 2).as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGFteqpazyGf",
        "colab_type": "code",
        "outputId": "134dd407-3fb7-4c62-85d6-89e4beb7c648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(1, 5, -2).as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbYu1EO-zyGt",
        "colab_type": "code",
        "outputId": "653818cf-fe3f-42e9-a72d-e60452d94ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(5, 1, -2).as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR1_DHNnzyG5",
        "colab_type": "code",
        "outputId": "7d12e17b-30d5-4ba2-889b-e76f1b9275e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(5, 1).as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbnpLAgHzyHD",
        "colab_type": "code",
        "outputId": "a1a48c1f-c9df-4c77-b1af-5ec8b88cb3f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Reduces the input dataset to a single element.\n",
        "tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, _: x + 1).numpy() \n",
        "#reduce(initial_state, reduce_func)\n",
        "#Reduces the input dataset to a single element.\n",
        "#The transformation calls reduce_func successively on every element \n",
        "#of the input dataset until the dataset is exhausted, \n",
        "#aggregating information in its internal state. \n",
        "#The initial_state argument is used for the initial state \n",
        "# and the final state is returned as the result."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T3YUFfmzyHJ",
        "colab_type": "code",
        "outputId": "24655561-b254-49c1-fb78-47dd4a5cb1e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, y: x + y).numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFKN4_8ozyHR",
        "colab_type": "code",
        "outputId": "eb5cfed7-88e1-4dad-a008-0f32f96266b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.repeat(3) \n",
        "list(dataset.as_numpy_iterator()) \n",
        "#Repeats this dataset so each original value is seen count times."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 1, 2, 3, 1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV5_YKF1zyHV",
        "colab_type": "code",
        "outputId": "1c2ec930-0bf7-48d1-aac2-825ad94984f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ] \n",
        "dataset = dataset.map(lambda x: x + 1) \n",
        "#  Maps map_func across the elements of this dataset.\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4, 5, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbIzPUlFzyHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.range(5) \n",
        "# `map_func` takes a single argument of type `tf.Tensor` with the same \n",
        "# shape and dtype. \n",
        "result = dataset.map(lambda x: x + 1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VftZ3OsCzyHi",
        "colab_type": "code",
        "outputId": "c6f76540-bfae-4a39-a3de-ebd6bd4beae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Each element is a tuple containing two `tf.Tensor` objects. \n",
        "elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz)\")] \n",
        "dataset = tf.data.Dataset.from_generator( \n",
        "    lambda: elements, (tf.int32, tf.string)) \n",
        "# `map_func` takes two arguments of type `tf.Tensor`. This function \n",
        "# projects out just the first component. \n",
        "result = dataset.map(lambda x_int, y_str: x_int) \n",
        "list(result.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t5vIHVXzyHn",
        "colab_type": "code",
        "outputId": "641a4759-7d0f-44df-bc2f-bb46bb872f3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import itertools \n",
        "import collections\n",
        "a = 1 # Integer element \n",
        "b = 2.0 # Float element \n",
        "c = (1, 2) # Tuple element with 2 components \n",
        "d = {\"a\": (2, 2), \"b\": 3} # Dict element with 3 components \n",
        "Point = collections.namedtuple(\"Point\", [\"x\", \"y\"]) # doctest: +SKIP Elements can be nested structures of tuples, named tuples, and dictionaries.\n",
        "e = Point(1, 2) # Named tuple # doctest: +SKIP \n",
        "f = tf.data.Dataset.range(10) # Dataset element \n",
        "e                  # readable __repr__ with a name=value style"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Point(x=1, y=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbhhElNRzyHu",
        "colab_type": "code",
        "outputId": "f6d09a1b-7fab-48d3-e658-aa55ae66d7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e[0] + e[1] # indexable like the plain tuple (1, 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrNyJS1bzyH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = e                # unpack like a regular tuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFvKTEPjzyH-",
        "colab_type": "code",
        "outputId": "68cdbd0a-6336-4a47-d273-3c0353ff2857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x, y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nezjMwkPzyIC",
        "colab_type": "code",
        "outputId": "f410203c-fb13-4fd1-815b-acb64614c6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e.x + e.y               # fields also accessible by name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIR0pqMqzyII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]).element_spec  # element_spec: The type specification of an element of this dataset."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isc_TOOezyIM",
        "colab_type": "code",
        "outputId": "be6ba6be-6d6c-4bf7-891f-c37994a80ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(100) \n",
        "def dataset_fn(ds): # transformation_func: A function that takes one Dataset argument and returns a Dataset.\n",
        "  return ds.filter(lambda x: x < 5) \n",
        "dataset = dataset.apply(dataset_fn) # apply enables chaining of custom Dataset transformations, which are represented as functions that take one Dataset argument and return a transformed Dataset.\n",
        "list(dataset.as_numpy_iterator()) # Returns an iterator which converts all elements of the dataset to numpy."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoJRgCFSzyIU",
        "colab_type": "code",
        "outputId": "f580a734-44e9-4e79-b2a2-4aa1266f8a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bztE1DAOzyIZ",
        "colab_type": "code",
        "outputId": "3b6c1af6-c4c6-414f-e12b-d5c540bf5fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "print(list(dataset.as_numpy_iterator())) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ZUx9DDzyIe",
        "colab_type": "code",
        "outputId": "cddd0551-5ac8-4bec-d45d-ddb50ca6665e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]), \n",
        "                                              'b': [5, 6]}) \n",
        "list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5}, # as_numpy_iterator() will preserve the nested structure of dataset elements.\n",
        "                                      {'a': (2, 4), 'b': 6}] "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaiusP8jzyIl",
        "colab_type": "code",
        "outputId": "f472d7f2-9551-49e3-f806-9eee639af014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(8)  \n",
        "dataset = dataset.batch(3) # Combines consecutive elements of this dataset into batches.\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtqBv9gXzyIr",
        "colab_type": "code",
        "outputId": "95c3df0c-d52c-4296-9d20-3300650e7fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(8) \n",
        "dataset = dataset.batch(3, drop_remainder=True) #  If your program depends on the batches having the same outer dimension, you should set the drop_remainder argument to True to prevent the smaller batch from being produced.\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioklpGSKzyIx",
        "colab_type": "code",
        "outputId": "93a15ca5-331e-471b-cc53-958c57038c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(5) \n",
        "dataset = dataset.map(lambda x: x**2) \n",
        "dataset = dataset.cache() #Caches the elements in this dataset.\n",
        "# The first time reading through the data will generate the data using \n",
        "# `range` and `map`. \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 4, 9, 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XtuMhhszyI4",
        "colab_type": "code",
        "outputId": "71ea8e2b-ff17-4b50-831b-71691f3ef317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Subsequent iterations read from the cache. \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 4, 9, 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GOPLCdnzyI8",
        "colab_type": "code",
        "outputId": "05904e7e-7265-4b3f-c711-19e7f0841513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ] \n",
        "b = tf.data.Dataset.range(4, 8)  # ==> [ 4, 5, 6, 7 ] \n",
        "ds = a.concatenate(b) # Creates a Dataset by concatenating the given dataset with this dataset.\n",
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmTwIWfHzyJA",
        "colab_type": "code",
        "outputId": "04e0315d-222d-4c98-9ae2-f6f8de8be703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Slicing a 1D tensor produces scalar tensor elements. \n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVT4COLwzyJJ",
        "colab_type": "code",
        "outputId": "8b6c5f93-f6dc-4e32-c5ba-872827c235cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Slicing a 1D tensor produces scalar tensor elements. \n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QZGsfQJzyJP",
        "colab_type": "code",
        "outputId": "544b5e29-9bdf-4904-c652-325e351897bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Slicing a tuple of 1D tensors produces tuple elements containing \n",
        "# scalar tensors. \n",
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6])) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 3, 5), (2, 4, 6)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzTLa731zyJT",
        "colab_type": "code",
        "outputId": "c40ae7c1-48cb-44e2-8029-24153eaef858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Dictionary structure is also preserved. \n",
        "dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]}) \n",
        "list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3}, \n",
        "                                      {'a': 2, 'b': 4}]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtKU5zUJzyJg",
        "colab_type": "code",
        "outputId": "83672cdf-df8a-4178-e9a9-d1eb54d3d395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# Two tensors can be combined into one Dataset object. \n",
        "features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor \n",
        "labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor \n",
        "dataset = dataset.from_tensor_slices((features, labels)) \n",
        "# Both the features and the labels tensors can be converted \n",
        "# to a Dataset object separately and combined after. \n",
        "features_dataset = dataset.from_tensor_slices(features) \n",
        "labels_dataset = dataset.from_tensor_slices(labels) \n",
        "dataset = dataset.zip((features_dataset, labels_dataset)) \n",
        "# A batched feature and label set can be converted to a Dataset \n",
        "# in similar fashion. \n",
        "batched_features = tf.constant([[[1, 3], [2, 3]], \n",
        "                                [[2, 1], [1, 2]], \n",
        "                                [[3, 3], [3, 2]]], shape=(3, 2, 2)) \n",
        "batched_labels = tf.constant([['A', 'A'], \n",
        "                              ['B', 'B'], \n",
        "                              ['A', 'B']], shape=(3, 2, 1)) \n",
        "dataset = dataset.from_tensor_slices((batched_features, batched_labels)) \n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([[1, 3],\n",
            "       [2, 3]], dtype=int32), array([[b'A'],\n",
            "       [b'A']], dtype=object))\n",
            "(array([[2, 1],\n",
            "       [1, 2]], dtype=int32), array([[b'B'],\n",
            "       [b'B']], dtype=object))\n",
            "(array([[3, 3],\n",
            "       [3, 2]], dtype=int32), array([[b'A'],\n",
            "       [b'B']], dtype=object))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oxILufvzyJj",
        "colab_type": "code",
        "outputId": "c76f7317-1e76-41c1-c78e-ee805eb7e575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.enumerate(start=5) #Enumerates the elements of this dataset.\n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 1)\n",
            "(6, 2)\n",
            "(7, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0e4NzCSzyJo",
        "colab_type": "code",
        "outputId": "0c570db7-5710-4f51-b958-e5beb8f83a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# The nested structure of the input dataset determines the structure of \n",
        "# elements in the resulting dataset. \n",
        "dataset = tf.data.Dataset.from_tensor_slices([(7, 8), (9, 10)]) \n",
        "dataset = dataset.enumerate() \n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, array([7, 8], dtype=int32))\n",
            "(1, array([ 9, 10], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKFU1g0izyJw",
        "colab_type": "code",
        "outputId": "c94d1026-53af-4589-d0cc-028fe2b19996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.filter(lambda x: x < 3) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl2FTn8rzyJ_",
        "colab_type": "code",
        "outputId": "a1e23731-e5ba-408b-f4f2-91b335b2b7f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# `tf.math.equal(x, y)` is required for equality comparison \n",
        "def filter_fn(x): \n",
        "  return tf.math.equal(x, 1) \n",
        "dataset = dataset.filter(filter_fn) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0y-_EExzyKC",
        "colab_type": "code",
        "outputId": "7161cac4-80a4-41de-9cc6-dc0ebf04941e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = dataset.from_tensor_slices([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) \n",
        "dataset = dataset.flat_map(lambda x: dataset.from_tensor_slices(x)) # Use flat_map if you want to make sure that the order of your dataset stays the same. \n",
        "#For example, to flatten a dataset of batches into a dataset of their elements\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bijMSAjxzyKH",
        "colab_type": "code",
        "outputId": "31246804-fec5-4a83-bbd4-697bdfe37b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def gen(): \n",
        "  for i in itertools.count(1): \n",
        "    yield (i, [1] * i) \n",
        "dataset = tf.data.Dataset.from_generator(gen,  #Creates a Dataset whose elements are generated by generator.\n",
        "     (tf.int64, tf.int64), \n",
        "     (tf.TensorShape([]), tf.TensorShape([None]))) \n",
        "list(dataset.take(3).as_numpy_iterator())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, array([1])), (2, array([1, 1])), (3, array([1, 1, 1]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alq0SFvIzyKN",
        "colab_type": "code",
        "outputId": "65f79a4f-fc5d-49d0-9b96-5cc7b8b1de24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensors([1, 2, 3]) # Creates a Dataset with a single element, comprising the given tensors.\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2, 3], dtype=int32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QGg5cIfzyKT",
        "colab_type": "code",
        "outputId": "c000d3c4-589d-4d0b-b34c-edc2665bc0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensors(([1, 2, 3], 'A')) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([1, 2, 3], dtype=int32), b'A')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy3Og8tFzyKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess 4 files concurrently, and interleave blocks of 16 records \n",
        "# from each file. \n",
        "filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\", \n",
        "             \"/var/data/file3.txt\", \"/var/data/file4.txt\"] \n",
        "dataset = tf.data.Dataset.from_tensor_slices(filenames) \n",
        "def parse_fn(filename): \n",
        "  return tf.data.Dataset.range(10) \n",
        "dataset = dataset.interleave(lambda x: \n",
        "    tf.data.TextLineDataset(x).map(parse_fn, num_parallel_calls=1), \n",
        "    cycle_length=4, block_length=16) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv5DZ7qszyKk",
        "colab_type": "code",
        "outputId": "ab4dd6bb-1063-4d6e-9c49-3b05d2e7f89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "dataset = dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ] \n",
        "# NOTE: New lines indicate \"block\" boundaries. \n",
        "dataset = dataset.interleave( \n",
        "    lambda x: dataset.from_tensors(x).repeat(6), \n",
        "    cycle_length=2, block_length=4) \n",
        "list(dataset.as_numpy_iterator()) \n",
        "#The cycle_length and block_length arguments control the order in which elements are produced. \n",
        "#cycle_length controls the number of input elements that are processed concurrently.\n",
        "#cycle_length input elements, open iterators on the returned Dataset objects, \n",
        "# and cycle through them producing block_length consecutive elements from each iterator, "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bvgKAHdzyKq",
        "colab_type": "code",
        "outputId": "1928b6d6-808a-4432-f629-9a37190b6863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "elements = [[1, 2], \n",
        "            [3, 4, 5], \n",
        "            [6, 7], \n",
        "            [8]] \n",
        "A = tf.data.Dataset.from_generator(lambda: iter(elements), tf.int32) \n",
        "# Pad to the smallest per-batch size that fits all elements. \n",
        "B = A.padded_batch(2, padded_shapes=[None]) \n",
        "for element in B.as_numpy_iterator(): \n",
        "  print(element) \n",
        "#Combines consecutive elements of this dataset into padded batches.\n",
        "#This transformation combines multiple consecutive elements of the input dataset into a single element."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 0]\n",
            " [3 4 5]]\n",
            "[[6 7]\n",
            " [8 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMQojFYZzyKz",
        "colab_type": "code",
        "outputId": "f77d7be6-79f0-46fc-e797-416895edebcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(3) \n",
        "dataset = dataset.prefetch(2) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgwxDxGwzyK-",
        "colab_type": "code",
        "outputId": "87ab12e8-d8ed-494c-fc2a-bdfd87df1e00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "a = tf.add(3, 5)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(8, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gsFWi9kzyLF",
        "colab_type": "code",
        "outputId": "ebd54667-68f2-4fbb-9009-811a51ddcdbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "a = tf.constant([[3, 5], [4, 8]])\n",
        "b = tf.constant([[1, 6], [2, 9]])\n",
        "tf.math.add_n([a, b, a])  # [[7, 16], [10, 25]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 7, 16],\n",
              "       [10, 25]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcGaF2EPzyLJ",
        "colab_type": "code",
        "outputId": "fd94837e-2f58-4e7c-e4f9-5f1229dd9622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Launch the graph in a session.\n",
        "with tf.compat.v1.Session() as ses:\n",
        "     # Build a graph.\n",
        "     a = tf.constant(5.0)\n",
        "     b = tf.constant(6.0)\n",
        "     c = tf.add(a, b)\n",
        "     # Evaluate the tensor `c`.\n",
        "     print(ses.run(c))\n",
        "# Using the `close()` method.\n",
        "ses.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmRvvl9fzyLT",
        "colab_type": "code",
        "outputId": "e6e95970-cd5b-49af-d88b-cbd662f528b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "x = 2\n",
        "y = 3\n",
        "op1 = tf.add(x, y)\n",
        "op2 = tf.multiply(x, y)\n",
        "op3 = tf.pow(op2, op1)\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    op3 = sess.run(op3)\n",
        "print(op3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-17e52c60323e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mop3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mop3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1166\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \"\"\"\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    303\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 305\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    306\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3511\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3512\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3514\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3588\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m       \u001b[0;31m# Actually obj is just the object it's referring to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1116\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m     raise AttributeError(\n\u001b[0;32m-> 1118\u001b[0;31m         \"Tensor.graph is meaningless when eager execution is enabled.\")\n\u001b[0m\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Tensor.graph is meaningless when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm6tsdbhzyLb",
        "colab_type": "code",
        "outputId": "fc1cca6d-4419-4d09-cf9c-c5465fa009a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Launch the graph in a session.\n",
        "with tf.compat.v1.Session() as ses:\n",
        "     # Build a graph.\n",
        "      x = 2\n",
        "      y = 3\n",
        "      add_op = tf.add(x, y)\n",
        "      mul_op = tf.multiply(x, y)\n",
        "      useless = tf.multiply(x, add_op)\n",
        "      pow_op = tf.pow(add_op, mul_op)\n",
        "      # Evaluate the tensor `c`.\n",
        "      print(ses.run(pow_op))\n",
        "# Using the `close()` method.\n",
        "ses.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0XxLTMPzyLi",
        "colab_type": "code",
        "outputId": "2bee8017-2a52-4b06-b5e3-76a3e4e98e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creates a graph.\n",
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "try: \n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
        "except: \n",
        "  # Invalid device or cannot modify virtual devices once initialized. \n",
        "  pass \n",
        "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='a')\n",
        "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='b')\n",
        "  c = tf.multiply(a, b)\n",
        "# Creates a session with log_device_placement set to True.\n",
        "#sess = tf.compat.v1.Session(config=tf.config.experimental(log_device_placement=True))\n",
        "# Runs the op.\n",
        "print(c)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 1.  4.  9. 16. 25. 36.], shape=(6,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTWoWwNhzyLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}